회귀 : 정확한 숫자
분류 : 보기 중 선택 문제(범위)

학습데이터 : 이론지
학습만을 위한 데이터 ( 가장 많은 비율 .. 80% )

검증데이터 : 모의고사 (공부정도 판단)
주기적으로 어느 정도 학습되었는지 확인 = 학습의 과정 ( 10% )

평가데이터 : 시험
학습 종료 후 최종 성능을 평가 ( 10% )

-overfitting [과적합]
훈련데이터 전용 학습 ( 특정 패턴, 디테일, 노이즈를 외움 )
새로운 데이터 적용성 떨어짐 == 일반화 능력 떨어짐
>> 데이터양 늘리기, 머신러닝 모델 복잡도 줄이기, 정규화기법 사용하기(규제)

-loss function [손실함수]
모델의 정확성을 수치화 ( 예측과 정답 비교 ) == loss가 적을수록 모델 성능 좋음
손실함수 종류
1. 회귀 : 평균 제곱 오차 [Mean Square Error]
2. 분류 : 교차 엔트로피 [Cross Entropy]
2+. 이진 분류 : 로그 손실 [Log Loss]
?? 손실을 줄이려면?
1. 파라미터의 최적화 ( 한번에 최적인 해를 구함 / 점진적, 반복적으로 해를 구함 )

+++++
회귀문제
1. 선형 회귀
선형 관계 이용 / 기본적 알고리즘

2. 라쏘/릿지 회귀
규제 기법 사용 / 일반화 성능이 향상

3. 결정트리 회귀
4. 서포트벡터 회귀

5. K최근접 이웃 회귀
주변 K개의 데이터 값으로 예측값 결정 / 데이터 의존도 높음

+++++
분류문제

1. 로지스틱 회귀
이진 분류 문제 / 확률 직접 예측 (확률 추정) ex) 승리할 확률 70% / 실패할 확률 30% 

2. 결정 트리 분류기
데이터 분할 결정 트리 / 직관적, 이해 쉬움

3. 랜덤 포레스트
여러 결정 트리 결합 (앙상블 기법) / 높은 정확도, *과적합 방지

4. 서포트 벡터머신
데이터 분리 경계 찾기 / 데이터가 복잡해도 가능
